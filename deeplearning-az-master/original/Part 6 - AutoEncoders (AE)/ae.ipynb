{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgYre1TxkfM1",
        "colab_type": "text"
      },
      "source": [
        "#Instalamos pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OORsGuoGkiJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS7ovYnWknlN",
        "colab_type": "text"
      },
      "source": [
        "#Clonamos el repositorio para obtener el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WK27vXwkrQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "215a8e6e-1d00-4cb9-aef0-b160c4a88860"
      },
      "source": [
        "!git clone https://github.com/joanby/deeplearning-az.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deeplearning-az'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 10153 (delta 25), reused 39 (delta 16), pack-reused 10096\u001b[K\n",
            "Receiving objects: 100% (10153/10153), 236.95 MiB | 36.84 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Checking out files: 100% (10108/10108), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YsQ0VYOtoCt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "b756a388-3be6-4ec4-a17b-8b9ead8a4983"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd7dRHyGk59L",
        "colab_type": "text"
      },
      "source": [
        "# Importar las librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-h2dwXIkt5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI6WdEzbk-Za",
        "colab_type": "text"
      },
      "source": [
        "# Importar el dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoeia18zk9jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = pd.read_csv(\"/content/deeplearning-az/datasets/Part 6 - AutoEncoders (AE)/ml-1m/movies.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users  = pd.read_csv(\"/content/deeplearning-az/datasets/Part 6 - AutoEncoders (AE)/ml-1m/users.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings  = pd.read_csv(\"/content/deeplearning-az/datasets/Part 6 - AutoEncoders (AE)/ml-1m/ratings.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSbdp-wUlFIX",
        "colab_type": "text"
      },
      "source": [
        "# Preparar el conjunto de entrenamiento y elconjunto de testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70yEO3RWlBg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = pd.read_csv(\"/content/deeplearning-az/datasets/Part 6 - AutoEncoders (AE)/ml-100k/u1.base\", sep = \"\\t\", header = None)\n",
        "training_set = np.array(training_set, dtype = \"int\")\n",
        "test_set = pd.read_csv(\"/content/deeplearning-az/datasets/Part 6 - AutoEncoders (AE)/ml-100k/u1.test\", sep = \"\\t\", header = None)\n",
        "test_set = np.array(test_set, dtype = \"int\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twATLFWTlMKM",
        "colab_type": "text"
      },
      "source": [
        "# Obtener el número de usuarios y de películas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CGpdosSlHXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSC4LbuvlT_I",
        "colab_type": "text"
      },
      "source": [
        "# Convertir los datos en un array X[u,i] con usuarios u en fila y películas i en columna\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmJQ-0fDlJZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_user in range(1, nb_users+1):\n",
        "        id_movies = data[:, 1][data[:, 0] == id_user]\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_user]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies-1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jno3ahx9lXB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7n1NZqylbCO",
        "colab_type": "text"
      },
      "source": [
        "# Convertir los datos a tensores de Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTRjUdQLlYdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JAFQYBflfqd",
        "colab_type": "text"
      },
      "source": [
        "# Crear la arquitectura de la Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbDUudP_ldDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC6XXcLklhrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqRbcjMIlo1P",
        "colab_type": "text"
      },
      "source": [
        "# Entrenar el SAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy_6yKN7lkAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "921a8746-6d44-4745-99fc-bd140fcd2510"
      },
      "source": [
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            output = sae.forward(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0)+1e-10) \n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector) ## sum(errors) / n_pelis_valoradas\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print(\"Epoch: \"+str(epoch)+\", Loss: \"+str(train_loss/s))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: tensor(1.7711)\n",
            "Epoch: 2, Loss: tensor(1.0967)\n",
            "Epoch: 3, Loss: tensor(1.0534)\n",
            "Epoch: 4, Loss: tensor(1.0385)\n",
            "Epoch: 5, Loss: tensor(1.0307)\n",
            "Epoch: 6, Loss: tensor(1.0267)\n",
            "Epoch: 7, Loss: tensor(1.0237)\n",
            "Epoch: 8, Loss: tensor(1.0218)\n",
            "Epoch: 9, Loss: tensor(1.0209)\n",
            "Epoch: 10, Loss: tensor(1.0196)\n",
            "Epoch: 11, Loss: tensor(1.0189)\n",
            "Epoch: 12, Loss: tensor(1.0183)\n",
            "Epoch: 13, Loss: tensor(1.0179)\n",
            "Epoch: 14, Loss: tensor(1.0172)\n",
            "Epoch: 15, Loss: tensor(1.0174)\n",
            "Epoch: 16, Loss: tensor(1.0169)\n",
            "Epoch: 17, Loss: tensor(1.0168)\n",
            "Epoch: 18, Loss: tensor(1.0164)\n",
            "Epoch: 19, Loss: tensor(1.0165)\n",
            "Epoch: 20, Loss: tensor(1.0162)\n",
            "Epoch: 21, Loss: tensor(1.0162)\n",
            "Epoch: 22, Loss: tensor(1.0159)\n",
            "Epoch: 23, Loss: tensor(1.0160)\n",
            "Epoch: 24, Loss: tensor(1.0160)\n",
            "Epoch: 25, Loss: tensor(1.0159)\n",
            "Epoch: 26, Loss: tensor(1.0156)\n",
            "Epoch: 27, Loss: tensor(1.0154)\n",
            "Epoch: 28, Loss: tensor(1.0150)\n",
            "Epoch: 29, Loss: tensor(1.0126)\n",
            "Epoch: 30, Loss: tensor(1.0110)\n",
            "Epoch: 31, Loss: tensor(1.0095)\n",
            "Epoch: 32, Loss: tensor(1.0086)\n",
            "Epoch: 33, Loss: tensor(1.0052)\n",
            "Epoch: 34, Loss: tensor(1.0052)\n",
            "Epoch: 35, Loss: tensor(1.0013)\n",
            "Epoch: 36, Loss: tensor(0.9998)\n",
            "Epoch: 37, Loss: tensor(0.9959)\n",
            "Epoch: 38, Loss: tensor(0.9956)\n",
            "Epoch: 39, Loss: tensor(0.9939)\n",
            "Epoch: 40, Loss: tensor(0.9936)\n",
            "Epoch: 41, Loss: tensor(0.9902)\n",
            "Epoch: 42, Loss: tensor(0.9897)\n",
            "Epoch: 43, Loss: tensor(0.9847)\n",
            "Epoch: 44, Loss: tensor(0.9847)\n",
            "Epoch: 45, Loss: tensor(0.9861)\n",
            "Epoch: 46, Loss: tensor(0.9861)\n",
            "Epoch: 47, Loss: tensor(0.9834)\n",
            "Epoch: 48, Loss: tensor(0.9864)\n",
            "Epoch: 49, Loss: tensor(0.9829)\n",
            "Epoch: 50, Loss: tensor(0.9835)\n",
            "Epoch: 51, Loss: tensor(0.9800)\n",
            "Epoch: 52, Loss: tensor(0.9848)\n",
            "Epoch: 53, Loss: tensor(0.9829)\n",
            "Epoch: 54, Loss: tensor(0.9824)\n",
            "Epoch: 55, Loss: tensor(0.9747)\n",
            "Epoch: 56, Loss: tensor(0.9707)\n",
            "Epoch: 57, Loss: tensor(0.9680)\n",
            "Epoch: 58, Loss: tensor(0.9715)\n",
            "Epoch: 59, Loss: tensor(0.9688)\n",
            "Epoch: 60, Loss: tensor(0.9671)\n",
            "Epoch: 61, Loss: tensor(0.9624)\n",
            "Epoch: 62, Loss: tensor(0.9646)\n",
            "Epoch: 63, Loss: tensor(0.9666)\n",
            "Epoch: 64, Loss: tensor(0.9665)\n",
            "Epoch: 65, Loss: tensor(0.9606)\n",
            "Epoch: 66, Loss: tensor(0.9623)\n",
            "Epoch: 67, Loss: tensor(0.9579)\n",
            "Epoch: 68, Loss: tensor(0.9579)\n",
            "Epoch: 69, Loss: tensor(0.9536)\n",
            "Epoch: 70, Loss: tensor(0.9554)\n",
            "Epoch: 71, Loss: tensor(0.9566)\n",
            "Epoch: 72, Loss: tensor(0.9552)\n",
            "Epoch: 73, Loss: tensor(0.9504)\n",
            "Epoch: 74, Loss: tensor(0.9541)\n",
            "Epoch: 75, Loss: tensor(0.9506)\n",
            "Epoch: 76, Loss: tensor(0.9505)\n",
            "Epoch: 77, Loss: tensor(0.9481)\n",
            "Epoch: 78, Loss: tensor(0.9497)\n",
            "Epoch: 79, Loss: tensor(0.9461)\n",
            "Epoch: 80, Loss: tensor(0.9466)\n",
            "Epoch: 81, Loss: tensor(0.9443)\n",
            "Epoch: 82, Loss: tensor(0.9464)\n",
            "Epoch: 83, Loss: tensor(0.9437)\n",
            "Epoch: 84, Loss: tensor(0.9446)\n",
            "Epoch: 85, Loss: tensor(0.9418)\n",
            "Epoch: 86, Loss: tensor(0.9433)\n",
            "Epoch: 87, Loss: tensor(0.9412)\n",
            "Epoch: 88, Loss: tensor(0.9417)\n",
            "Epoch: 89, Loss: tensor(0.9411)\n",
            "Epoch: 90, Loss: tensor(0.9419)\n",
            "Epoch: 91, Loss: tensor(0.9389)\n",
            "Epoch: 92, Loss: tensor(0.9392)\n",
            "Epoch: 93, Loss: tensor(0.9373)\n",
            "Epoch: 94, Loss: tensor(0.9386)\n",
            "Epoch: 95, Loss: tensor(0.9363)\n",
            "Epoch: 96, Loss: tensor(0.9380)\n",
            "Epoch: 97, Loss: tensor(0.9351)\n",
            "Epoch: 98, Loss: tensor(0.9368)\n",
            "Epoch: 99, Loss: tensor(0.9348)\n",
            "Epoch: 100, Loss: tensor(0.9363)\n",
            "Epoch: 101, Loss: tensor(0.9347)\n",
            "Epoch: 102, Loss: tensor(0.9356)\n",
            "Epoch: 103, Loss: tensor(0.9339)\n",
            "Epoch: 104, Loss: tensor(0.9352)\n",
            "Epoch: 105, Loss: tensor(0.9325)\n",
            "Epoch: 106, Loss: tensor(0.9340)\n",
            "Epoch: 107, Loss: tensor(0.9319)\n",
            "Epoch: 108, Loss: tensor(0.9332)\n",
            "Epoch: 109, Loss: tensor(0.9312)\n",
            "Epoch: 110, Loss: tensor(0.9324)\n",
            "Epoch: 111, Loss: tensor(0.9309)\n",
            "Epoch: 112, Loss: tensor(0.9320)\n",
            "Epoch: 113, Loss: tensor(0.9303)\n",
            "Epoch: 114, Loss: tensor(0.9314)\n",
            "Epoch: 115, Loss: tensor(0.9296)\n",
            "Epoch: 116, Loss: tensor(0.9300)\n",
            "Epoch: 117, Loss: tensor(0.9288)\n",
            "Epoch: 118, Loss: tensor(0.9297)\n",
            "Epoch: 119, Loss: tensor(0.9283)\n",
            "Epoch: 120, Loss: tensor(0.9293)\n",
            "Epoch: 121, Loss: tensor(0.9278)\n",
            "Epoch: 122, Loss: tensor(0.9286)\n",
            "Epoch: 123, Loss: tensor(0.9272)\n",
            "Epoch: 124, Loss: tensor(0.9286)\n",
            "Epoch: 125, Loss: tensor(0.9265)\n",
            "Epoch: 126, Loss: tensor(0.9273)\n",
            "Epoch: 127, Loss: tensor(0.9264)\n",
            "Epoch: 128, Loss: tensor(0.9271)\n",
            "Epoch: 129, Loss: tensor(0.9258)\n",
            "Epoch: 130, Loss: tensor(0.9264)\n",
            "Epoch: 131, Loss: tensor(0.9254)\n",
            "Epoch: 132, Loss: tensor(0.9258)\n",
            "Epoch: 133, Loss: tensor(0.9244)\n",
            "Epoch: 134, Loss: tensor(0.9252)\n",
            "Epoch: 135, Loss: tensor(0.9247)\n",
            "Epoch: 136, Loss: tensor(0.9253)\n",
            "Epoch: 137, Loss: tensor(0.9236)\n",
            "Epoch: 138, Loss: tensor(0.9244)\n",
            "Epoch: 139, Loss: tensor(0.9230)\n",
            "Epoch: 140, Loss: tensor(0.9227)\n",
            "Epoch: 141, Loss: tensor(0.9225)\n",
            "Epoch: 142, Loss: tensor(0.9225)\n",
            "Epoch: 143, Loss: tensor(0.9217)\n",
            "Epoch: 144, Loss: tensor(0.9217)\n",
            "Epoch: 145, Loss: tensor(0.9214)\n",
            "Epoch: 146, Loss: tensor(0.9222)\n",
            "Epoch: 147, Loss: tensor(0.9212)\n",
            "Epoch: 148, Loss: tensor(0.9206)\n",
            "Epoch: 149, Loss: tensor(0.9206)\n",
            "Epoch: 150, Loss: tensor(0.9212)\n",
            "Epoch: 151, Loss: tensor(0.9208)\n",
            "Epoch: 152, Loss: tensor(0.9211)\n",
            "Epoch: 153, Loss: tensor(0.9202)\n",
            "Epoch: 154, Loss: tensor(0.9202)\n",
            "Epoch: 155, Loss: tensor(0.9195)\n",
            "Epoch: 156, Loss: tensor(0.9195)\n",
            "Epoch: 157, Loss: tensor(0.9192)\n",
            "Epoch: 158, Loss: tensor(0.9192)\n",
            "Epoch: 159, Loss: tensor(0.9184)\n",
            "Epoch: 160, Loss: tensor(0.9190)\n",
            "Epoch: 161, Loss: tensor(0.9187)\n",
            "Epoch: 162, Loss: tensor(0.9182)\n",
            "Epoch: 163, Loss: tensor(0.9178)\n",
            "Epoch: 164, Loss: tensor(0.9180)\n",
            "Epoch: 165, Loss: tensor(0.9178)\n",
            "Epoch: 166, Loss: tensor(0.9177)\n",
            "Epoch: 167, Loss: tensor(0.9175)\n",
            "Epoch: 168, Loss: tensor(0.9174)\n",
            "Epoch: 169, Loss: tensor(0.9169)\n",
            "Epoch: 170, Loss: tensor(0.9174)\n",
            "Epoch: 171, Loss: tensor(0.9165)\n",
            "Epoch: 172, Loss: tensor(0.9167)\n",
            "Epoch: 173, Loss: tensor(0.9161)\n",
            "Epoch: 174, Loss: tensor(0.9168)\n",
            "Epoch: 175, Loss: tensor(0.9160)\n",
            "Epoch: 176, Loss: tensor(0.9164)\n",
            "Epoch: 177, Loss: tensor(0.9159)\n",
            "Epoch: 178, Loss: tensor(0.9160)\n",
            "Epoch: 179, Loss: tensor(0.9158)\n",
            "Epoch: 180, Loss: tensor(0.9158)\n",
            "Epoch: 181, Loss: tensor(0.9152)\n",
            "Epoch: 182, Loss: tensor(0.9155)\n",
            "Epoch: 183, Loss: tensor(0.9150)\n",
            "Epoch: 184, Loss: tensor(0.9152)\n",
            "Epoch: 185, Loss: tensor(0.9148)\n",
            "Epoch: 186, Loss: tensor(0.9150)\n",
            "Epoch: 187, Loss: tensor(0.9147)\n",
            "Epoch: 188, Loss: tensor(0.9142)\n",
            "Epoch: 189, Loss: tensor(0.9148)\n",
            "Epoch: 190, Loss: tensor(0.9150)\n",
            "Epoch: 191, Loss: tensor(0.9143)\n",
            "Epoch: 192, Loss: tensor(0.9143)\n",
            "Epoch: 193, Loss: tensor(0.9138)\n",
            "Epoch: 194, Loss: tensor(0.9143)\n",
            "Epoch: 195, Loss: tensor(0.9135)\n",
            "Epoch: 196, Loss: tensor(0.9138)\n",
            "Epoch: 197, Loss: tensor(0.9132)\n",
            "Epoch: 198, Loss: tensor(0.9136)\n",
            "Epoch: 199, Loss: tensor(0.9128)\n",
            "Epoch: 200, Loss: tensor(0.9132)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENHGLCyiluJn",
        "colab_type": "text"
      },
      "source": [
        "# Evaluar el conjunto de test en nuestro SAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAL0ZZOhlruw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = sae.forward(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0)+1e-10) \n",
        "        test_loss += np.sqrt(loss.data*mean_corrector) ## sum(errors) / n_pelis_valoradas\n",
        "        s += 1."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quy4q1UFlwfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbece7af-feb4-4943-aaf0-d4b9f8fc6164"
      },
      "source": [
        "print(\"Test Loss: \"+str(test_loss/s))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: tensor(0.9549)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}