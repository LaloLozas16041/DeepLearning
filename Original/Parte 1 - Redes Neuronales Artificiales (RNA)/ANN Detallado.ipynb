{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd818e64",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Instalación de Dependencias\n",
    "Instalación de todas las bibliotecas necesarias para el proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a361f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install sklearn keras tensorflow pandas numpy matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1bd3f",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Importación de Librerías\n",
    "Importamos las librerías necesarias para el análisis de datos, construcción de modelos y visualización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99585b4",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Carga de Datos y Análisis Exploratorio de Datos (EDA)\n",
    "Procedemos a cargar el conjunto de datos y realizar un análisis exploratorio para obtener insights preliminares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb789b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = 'Churn_Modelling.csv'\n",
    "dataset = pd.read_csv(data_path)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Exited', data=dataset)\n",
    "plt.title('Distribución de la Variable Objetivo')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(dataset.corr(), annot=True, fmt='.2f')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a9cb06",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Preprocesamiento de Datos\n",
    "Detalle de cómo se codifican las variables categóricas y se escalan las características para la preparación de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X['Geography'] = labelencoder_X_1.fit_transform(X['Geography'])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X['Gender'] = labelencoder_X_2.fit_transform(X['Gender'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22665687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construcción de la RNA\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compilación y entrenamiento\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33feb1b6",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Evaluación del Modelo y Métricas de Desempeño\n",
    "Aquí evaluamos el modelo utilizando la matriz de confusión y calculamos métricas de rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('Matriz de Confusión:\\n', cm)\n",
    "print('\\nAccuracy:', accuracy)\n",
    "print('F1-Score:', f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd6963",
   "metadata": {},
   "source": [
    "\n",
    "# 7. Conclusión Ejecutiva\n",
    "Resumen ejecutivo del análisis realizado, incluyendo conclusiones clave, interpretaciones y posibles recomendaciones basadas en los resultados del modelo.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
